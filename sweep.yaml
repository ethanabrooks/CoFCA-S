program: starcraft.py
method: bayes
metric:
  goal: maximize
  name: reward
parameters:
  conv_hidden_size:
    distribution: categorical
    values:
      - 50
      - 75
      - 100
      - 150
  entropy_coef:
    distribution: categorical
    values:
      - 0.015
      - 0.02
      - 0.025
  hidden_size:
    distribution: categorical
    values:
      - 50
      - 100
      - 150
      - 200
      - 250
  learning_rate:
    distribution: categorical
    values:
      - 0.0005
      - 0.001
      - 0.0015
      - 0.002
      - 0.0025
  lower_embed_size:
    distribution: categorical
    values:
      - 50
      - 75
      - 100
  next_actions_embed_size:
    distribution: categorical
    values:
      - 25
      - 50
      - 75
      - 100
  num_batch:
    distribution: categorical
    values:
      - 1
      - 2
  num_edges:
    distribution: categorical
    values:
      - 1
  num_processes:
    distribution: categorical
    values:
      - 60
      - 70
      - 80
      - 90
      - 100
      - 110
      - 120
      - 130
      - 140
      - 150
  ppo_epoch:
    distribution: categorical
    values:
      - 5
      - 10
      - 15
      - 20
  tgt_success_rate:
    distribution: categorical
    values:
      - 0.75
      - 0.8
      - 0.85
      - 0.9
  train_steps:
    distribution: categorical
    values:
      - 25
      - 30
      - 35
