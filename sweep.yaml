program: starcraft.py
method: bayes
metric:
  goal: maximize
  name: reward
parameters:
  conv_hidden_size:
    distribution: categorical
    values:
      - 25
      - 50
      - 75
      - 100
  entropy_coef:
    distribution: categorical
    values:
      - 0.015
      - 0.02
      - 0.025
  hidden_size:
    distribution: categorical
    values:
      - 50
      - 100
      - 150
      - 200
      - 250
  learning_rate:
    distribution: categorical
    values:
      - 0.001
      - 0.0015
      - 0.002
      - 0.0025
      - 0.003
      - 0.0035
  lower_embed_size:
    distribution: categorical
    values:
      - 25
      - 50
      - 75
      - 100
  next_actions_embed_size:
    distribution: categorical
    values:
      - 25
      - 50
      - 75
      - 100
  num_batch:
    distribution: categorical
    values:
      - 1
      - 2
      - 4
  num_edges:
    distribution: categorical
    values:
      - 1
  num_processes:
    distribution: categorical
    values:
      - 16
      - 32
      - 64
      - 128
  ppo_epoch:
    distribution: categorical
    values:
      - 3
      - 4
      - 10
      - 15
      - 20
  tgt_success_rate:
    distribution: categorical
    values:
      - 0.75
      - 0.8
      - 0.85
      - 0.9
  train_steps:
    distribution: categorical
    values:
      - 20
      - 25
      - 30
      - 35
